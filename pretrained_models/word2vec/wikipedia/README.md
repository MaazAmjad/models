# Pretrained Word2vec model on whole wikipedia corpus.

## Model Description

- Model trained on 78482 urdu wikipedia posts.
- Model vector size is 300.
- Download link (https://drive.google.com/uc?export=download&id=1yz8RfJeg65QByLs1aJUORtPujHYx_oQP)
- Semantic accuracy: 59.59%
- Syntactic accuracy: 37.50%
- Model can be load using python gensim package.

## Code

```python

import gensim, logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)


model = gensim.models.KeyedVectors.load_word2vec_format('urdu_wikipedia_vector300.bin', binary=True)

print(model.most_similar("پاکستان"))
[('افغانستان', 0.534391462802887)
, ('پاکستانی', 0.527515172958374)
, ('بھارت', 0.5176973342895508)
, ('زمبابوے', 0.5033701062202454) ]

print(model.most_similar(positive=['دہلی', 'پاکستان'], negative=['پنجاب'],topn=5))
[('دلی', 0.47923001646995544)
, ('انڈیا', 0.4310738444328308)
, ('بھارت', 0.4303123652935028)
, ('پاکستانی', 0.42918506264686584)
, ('بیجنگ', 0.42072150111198425)]

print(model.most_similar(positive=['ٹوکیو', 'پاکستان'], negative=['اسلام_آباد']))
[('جاپان', 0.518461287021637),
 ('جاپانی', 0.42522647976875305),
 ('بھارت', 0.3991791605949402),
 ('دنیا', 0.3974219858646393),
 ('چین', 0.3774305582046509),
 ('اوساکا', 0.3636421859264374),
 ('جاپان،', 0.35131868720054626),
 ('انڈیا', 0.3293466866016388),
 ('عالمی', 0.32560476660728455),
 ('جاپانیوں', 0.3245166540145874)]
 
print(model.most_similar(positive=['بھائی', 'لڑکی'], negative=['لڑکا']))
[('بہن', 0.5513333082199097),
 ('والد', 0.532108724117279),
 ('بیٹی', 0.5085018873214722),
 ('والدہ', 0.48878273367881775),
 ('کوقتل', 0.46216732263565063),
 ('بھائیوں', 0.45481085777282715),
 ('پولیس', 0.4398535490036011),
 ('باپ', 0.439206600189209),
 ('کزن', 0.417349249124527),
 ('خاتون', 0.4159335494041443)]
 
print(model.most_similar(positive=['دلہن', 'شوہر'], negative=['دولہا']))
[('بیوی', 0.6536001563072205),
 ('خاوند', 0.6006074547767639),
 ('طلاق', 0.5600955486297607),
 ('خاتون', 0.5458393692970276),
 ('شادی', 0.5421558022499084),
 ('بیٹی', 0.5145429968833923),
 ('اداکارہ', 0.4982667863368988),
 ('ماں', 0.4932785630226135),
 ('عورت', 0.476948082447052),
 ('اہلیہ', 0.4722379744052887)]
 
print(model.most_similar(positive=['ملکہ', 'باپ'], negative=['بادشاہ']))
[('ماں', 0.5100770592689514),
 ('بیٹی', 0.4709329605102539),
 ('بیٹے', 0.42628371715545654),
 ('رشتے', 0.3735599219799042),
 ('بیٹوں', 0.3722909986972809),
 ('بہو', 0.37172698974609375),
 ('بیوی', 0.3640066385269165),
 ('بچی', 0.36133867502212524),
 ('شوہر', 0.36050519347190857),
 ('بہن', 0.3537209630012512)]
 

```